{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84220874-e23a-4908-b23d-7d0315dcca9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 03:27:33.108167: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-19 03:27:33.268684: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-19 03:27:33.269843: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-19 03:27:34.160506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Convolution1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "size = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2775bf-27f2-450c-91c0-68357343ed0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_url = '/home/thinker/NLP/NLP/FromScratch/RNN_LSTM_GRU/error detection/data/data/train_data.csv'\n",
    "test_url = '/home/thinker/NLP/NLP/FromScratch/RNN_LSTM_GRU/error detection/data/data/test_data.csv'\n",
    "df_train = pd.read_csv(train_url)\n",
    "df_test = pd.read_csv(test_url)\n",
    "stop_words_df = pd.read_excel('/home/thinker/NLP/NLP/FromScratch/RNN_LSTM_GRU/error detection/data/stopwords_bangla.xlsx',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c9786e-d641-498e-a452-582ea1e66096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set([word.strip() for word in stop_words_df['words']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0afe04-291e-4925-8408-e5c67a9a7b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(x):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    x = html_pattern.sub(r'', x)\n",
    "    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n",
    "    return x\n",
    "df_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\n",
    "df_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4d023f-0bc7-45fd-af49-0f3f2e069121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "MAX_FEATURES = 6000\n",
    "EMBED_SIZE = 128\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(df_train['Comment'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df_train['Comment'])\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(df_test['Comment'])\n",
    "RNN_CELL_SIZE = 32\n",
    "MAX_LEN = 60   # Since our mean length is 56.6\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen=MAX_LEN)\n",
    "X_test = pad_sequences(list_tokenized_test,maxlen=MAX_LEN)\n",
    "y_train = df_train['Error']\n",
    "y_test = df_test['Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8b04f8-5cb9-4de8-8fd6-b373bea9174c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    " \n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eacc747-a3e9-425f-9e8d-eb9c9bdec66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_LEN,), dtype=\"int32\")\n",
    "embedded_sequences = Embedding(MAX_FEATURES, EMBED_SIZE)(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e56ecee3-2394-4fac-9214-0c08e630b114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm = Bidirectional(LSTM(RNN_CELL_SIZE, return_sequences = True), name=\"bi_lstm_0\")(embedded_sequences)# Getting our LSTM outputs\n",
    "(lstm, forward_h, forward_c, backward_h, backward_c) = Bidirectional(LSTM(RNN_CELL_SIZE, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e303b752-25d9-4f9e-a06b-36aa10f9c47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "context_vector, attention_weights = Attention(10)(lstm, state_h)\n",
    "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.05)(dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
    "model = keras.Model(inputs=sequence_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b686a5-7939-441e-b3ad-57ae6f4e0d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b6769ca-3ea1-48f1-816c-ae85315a2a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65/65 [==============================] - 10s 76ms/step - loss: 0.6827 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3698.0000 - fn: 2730.0000 - accuracy: 0.5753 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5114 - val_loss: 0.6735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 953.0000 - val_fn: 655.0000 - val_accuracy: 0.5927 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6181\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 4s 54ms/step - loss: 0.6360 - tp: 637.0000 - fp: 256.0000 - tn: 3442.0000 - fn: 2093.0000 - accuracy: 0.6346 - precision: 0.7133 - recall: 0.2333 - auc: 0.6625 - val_loss: 0.6090 - val_tp: 229.0000 - val_fp: 98.0000 - val_tn: 855.0000 - val_fn: 426.0000 - val_accuracy: 0.6741 - val_precision: 0.7003 - val_recall: 0.3496 - val_auc: 0.6924\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.4434 - tp: 1901.0000 - fp: 414.0000 - tn: 3284.0000 - fn: 829.0000 - accuracy: 0.8066 - precision: 0.8212 - recall: 0.6963 - auc: 0.8646 - val_loss: 0.6262 - val_tp: 344.0000 - val_fp: 202.0000 - val_tn: 751.0000 - val_fn: 311.0000 - val_accuracy: 0.6810 - val_precision: 0.6300 - val_recall: 0.5252 - val_auc: 0.7097\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.3229 - tp: 2176.0000 - fp: 266.0000 - tn: 3432.0000 - fn: 554.0000 - accuracy: 0.8724 - precision: 0.8911 - recall: 0.7971 - auc: 0.9286 - val_loss: 0.7447 - val_tp: 384.0000 - val_fp: 247.0000 - val_tn: 706.0000 - val_fn: 271.0000 - val_accuracy: 0.6779 - val_precision: 0.6086 - val_recall: 0.5863 - val_auc: 0.7067\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 4s 56ms/step - loss: 0.2556 - tp: 2283.0000 - fp: 201.0000 - tn: 3497.0000 - fn: 447.0000 - accuracy: 0.8992 - precision: 0.9191 - recall: 0.8363 - auc: 0.9552 - val_loss: 0.8457 - val_tp: 353.0000 - val_fp: 208.0000 - val_tn: 745.0000 - val_fn: 302.0000 - val_accuracy: 0.6828 - val_precision: 0.6292 - val_recall: 0.5389 - val_auc: 0.6991\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 5\n",
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d982f8-9299-44a9-8216-5436c5c6c934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d715188d-9564-466b-8941-4abcd4332b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Correct       0.68      0.78      0.73      1167\n",
      "   Incorrect       0.62      0.48      0.54       844\n",
      "\n",
      "    accuracy                           0.66      2011\n",
      "   macro avg       0.65      0.63      0.63      2011\n",
      "weighted avg       0.65      0.66      0.65      2011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred, target_names = ['Correct','Incorrect']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
