{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1382412,"sourceType":"datasetVersion","datasetId":806606},{"sourceId":7455253,"sourceType":"datasetVersion","datasetId":4339552}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dropout\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nSTOPWORDS = set(stopwords.words('english'))\n\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T13:57:17.961062Z","iopub.execute_input":"2024-01-22T13:57:17.961461Z","iopub.status.idle":"2024-01-22T13:57:17.968683Z","shell.execute_reply.started":"2024-01-22T13:57:17.961430Z","shell.execute_reply":"2024-01-22T13:57:17.967755Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def text_to_word_list(text):\n    text = text.split()\n    return text\n\ndef replace_strings(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           u\"\\u00C0-\\u017F\"          #latin\n                           u\"\\u2000-\\u206F\"          #generalPunctuations\n                               \n                           \"]+\", flags=re.UNICODE)\n    english_pattern=re.compile('[a-zA-Z0-9]+', flags=re.I)\n    #latin_pattern=re.compile('[A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00f6\\u00f8-\\u00ff\\s]*',)\n    \n    text=emoji_pattern.sub(r'', text)\n    text=english_pattern.sub(r'', text)\n\n    return text\n\ndef remove_punctuations(my_str):\n    # define punctuation\n    punctuations = '''```\u0012\u0010\u0002\b`\u0007\b£|¢|\u0007Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’,<>./?@#$%^&*_~‘—॥”‰⚽️✌�￰৷￰'''\n    \n    no_punct = \"\"\n    for char in my_str:\n        if char not in punctuations:\n            no_punct = no_punct + char\n\n    # display the unpunctuated string\n    return no_punct\n\n\n\ndef joining(text):\n    out=' '.join(text)\n    return out\n\ndef preprocessing(text):\n    out=remove_punctuations(replace_strings(text))\n    return out","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T13:57:22.788201Z","iopub.execute_input":"2024-01-22T13:57:22.789010Z","iopub.status.idle":"2024-01-22T13:57:22.797061Z","shell.execute_reply.started":"2024-01-22T13:57:22.788980Z","shell.execute_reply":"2024-01-22T13:57:22.796163Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_url = '/kaggle/input/rev-corr/train8020.csv'\ntest_url = '/kaggle/input/rev-corr/test8020.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)\nSTOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T13:58:00.634113Z","iopub.execute_input":"2024-01-22T13:58:00.634612Z","iopub.status.idle":"2024-01-22T13:58:01.191574Z","shell.execute_reply.started":"2024-01-22T13:58:00.634580Z","shell.execute_reply":"2024-01-22T13:58:01.190655Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_train['Comment'] = df_train.Comment.apply(lambda x: preprocessing(str(x)))\ndf_test['Comment'] = df_test.Comment.apply(lambda x:preprocessing(str(x)))\ndf = pd.concat([df_train,df_test],ignore_index = True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T13:58:07.386039Z","iopub.execute_input":"2024-01-22T13:58:07.386396Z","iopub.status.idle":"2024-01-22T13:58:08.175145Z","shell.execute_reply.started":"2024-01-22T13:58:07.386367Z","shell.execute_reply":"2024-01-22T13:58:08.174025Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"set(df['Category'].values)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T13:58:11.238259Z","iopub.execute_input":"2024-01-22T13:58:11.238606Z","iopub.status.idle":"2024-01-22T13:58:11.246745Z","shell.execute_reply.started":"2024-01-22T13:58:11.238578Z","shell.execute_reply":"2024-01-22T13:58:11.245861Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'Code Switching', 'Correct', 'Grammatical', 'Multiple Errors', 'Spelling'}"},"metadata":{}}]},{"cell_type":"code","source":"def encode(s):\n    d = {\n        \"Code Switching\":0,\n        \"Grammatical\":1,\n        \"Multiple Errors\":2,\n        \"Spelling\":3,\n        \"Correct\":4\n    }\n    if s in d:\n        return d[s]\n    else:\n        return 4\ndf['Category'] = df.Category.apply(lambda x: encode(x))\ndf_train['Category'] = df_train.Category.apply(lambda x: encode(x))\ndf_test['Category'] = df_test.Category.apply(lambda x: encode(x))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T14:00:06.401244Z","iopub.execute_input":"2024-01-22T14:00:06.402039Z","iopub.status.idle":"2024-01-22T14:00:06.471458Z","shell.execute_reply.started":"2024-01-22T14:00:06.402003Z","shell.execute_reply":"2024-01-22T14:00:06.470594Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, Conv1D, LSTM, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\ndata = df_train['Comment']\nlabels = df_train['Category']\n# Tokenize text data\nmax_words = 1000\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(df['Comment'])\nsequences = tokenizer.texts_to_sequences(data)\nword_index = tokenizer.word_index\nmax_sequence_length = 100  # Adjust this based on your data\n\n# Pad sequences\nX = pad_sequences(sequences, maxlen=max_sequence_length)\n\n# One-hot encode labels\nY = tf.keras.utils.to_categorical(labels, num_classes=5)\n\n# Create CNN-LSTM model\nmodel = Sequential()\nmodel.add(Embedding(max_words, 100, input_length=max_sequence_length))\nmodel.add(Conv1D(128, 5, activation='relu'))\nmodel.add(LSTM(64))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X, Y, epochs=5, batch_size=16, validation_split=0.2)\n\n# Evaluate the model on test data (replace with your test data)\ntest_data = df_test['Comment'] # Replace with your actual test data\ntest_labels = df_test['Category']  # Replace with your actual test labels\n\ntest_sequences = tokenizer.texts_to_sequences(test_data)\nX_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\nY_test = tf.keras.utils.to_categorical(test_labels, num_classes=5)\n\nloss, accuracy = model.evaluate(X_test, Y_test)\nprint(f'Test Loss: {loss}, Test Accuracy: {accuracy}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T14:00:15.463751Z","iopub.execute_input":"2024-01-22T14:00:15.464114Z","iopub.status.idle":"2024-01-22T14:01:26.817708Z","shell.execute_reply.started":"2024-01-22T14:00:15.464085Z","shell.execute_reply":"2024-01-22T14:01:26.816736Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1005/1005 [==============================] - 32s 25ms/step - loss: 1.2115 - accuracy: 0.5269 - val_loss: 1.4913 - val_accuracy: 0.0020\nEpoch 2/5\n1005/1005 [==============================] - 9s 9ms/step - loss: 1.1103 - accuracy: 0.5572 - val_loss: 1.2681 - val_accuracy: 0.2639\nEpoch 3/5\n1005/1005 [==============================] - 9s 9ms/step - loss: 1.0304 - accuracy: 0.5935 - val_loss: 1.2423 - val_accuracy: 0.3311\nEpoch 4/5\n1005/1005 [==============================] - 8s 8ms/step - loss: 0.9400 - accuracy: 0.6310 - val_loss: 1.5942 - val_accuracy: 0.2776\nEpoch 5/5\n1005/1005 [==============================] - 8s 8ms/step - loss: 0.8479 - accuracy: 0.6630 - val_loss: 1.7769 - val_accuracy: 0.2736\n157/157 [==============================] - 1s 4ms/step - loss: 1.4262 - accuracy: 0.4636\nTest Loss: 1.4261767864227295, Test Accuracy: 0.4635603427886963\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\ny_pred = model.predict(X_test)\n\n# Calculate macro recall\nmacro_recall = recall_score(Y_test.argmax(axis=1), y_pred.argmax(axis=1), average='macro')\nmacro_precision = precision_score(Y_test.argmax(axis=1), y_pred.argmax(axis=1), average='macro')\n# Print the results\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n  Macro Recall: {:0.3f}\\n  Macro Precision: {:0.3f}'.format(loss, accuracy, macro_recall, macro_precision))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-22T14:01:26.819513Z","iopub.execute_input":"2024-01-22T14:01:26.819810Z","iopub.status.idle":"2024-01-22T14:01:27.834122Z","shell.execute_reply.started":"2024-01-22T14:01:26.819784Z","shell.execute_reply":"2024-01-22T14:01:27.832469Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 1s 3ms/step\nTest set\n  Loss: 1.426\n  Accuracy: 0.464\n  Macro Recall: 0.310\n  Macro Precision: 0.349\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}